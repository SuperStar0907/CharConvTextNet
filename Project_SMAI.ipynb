{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install matplotlib\n",
    "! pip install numpy\n",
    "! pip install torch\n",
    "! pip install pandas\n",
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as seq\n",
    "from torch.nn import Conv1d as c1d\n",
    "from torch.nn import Linear as l_n\n",
    "from torch.nn import ReLU as rel\n",
    "from torch.nn import Dropout as drop\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import nll_loss as nll_loss\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from torch.nn import MaxPool1d as m1d\n",
    "import os\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import tabulate\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterConvolutionNetwork(nn.Module):                                       # Class for Character Convolution Network (CCN) \n",
    "    def __init__(self, n_classes=4, input_length=1014, input_dim=68):\n",
    "        self.ker_siz=[7,7,3,3,3,3]\n",
    "        super(CharacterConvolutionNetwork, self).__init__()\n",
    "        self.conv1 = seq(c1d(input_dim, 256, kernel_size=self.ker_siz[0]), rel(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        self.conv2 = seq(c1d(256, 256, kernel_size=self.ker_siz[1], padding=0), rel(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        self.conv3 = seq(c1d(256, 256, kernel_size=self.ker_siz[2], padding=0), rel())\n",
    "        self.conv4 = seq(c1d(256, 256, kernel_size=self.ker_siz[3], padding=0), rel())\n",
    "        self.conv5 = seq(c1d(256, 256, kernel_size=self.ker_siz[4], padding=0), rel())\n",
    "        self.conv6 = seq(c1d(256, 256, kernel_size=self.ker_siz[5], padding=0), rel(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "\n",
    "        dimension = int((input_length - 96) / 27 * 256)\n",
    "        self.fc1 = seq(l_n(dimension, 1024), drop(0.5))\n",
    "        self.fc2 = seq(l_n(1024, 1024), drop(0.5))\n",
    "        self.fc3 = l_n(1024, n_classes)\n",
    "        mn = 0.0\n",
    "        std_dev = 0.05\n",
    "        self._weights(mean=mn, std=std_dev)\n",
    "\n",
    "    def _weights(self, mean=0, std=0.05):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, c1d) or isinstance(module, l_n):\n",
    "                module.weight.data.normal_(mean, std)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = inp.transpose(1, 2)\n",
    "        y = self.conv1(inp)\n",
    "        y = self.conv2(y)\n",
    "        y = self.conv3(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.conv5(y)\n",
    "        y = self.conv6(y)\n",
    "        y = y.view(y.size(0), -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.fc3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characterConvolutionNetwork = CharacterConvolutionNetwork(4)\n",
    "print(characterConvolutionNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'./dataset/train.csv')\n",
    "train_df=pd.DataFrame(data,columns=[\"class\",\"title\",\"desc\"])\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'./dataset/test.csv')\n",
    "test_df=pd.DataFrame(data,columns=[\"class\",\"title\",\"desc\"])\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self,df, max_length=1014):\n",
    "#         self.data_path = data_path\n",
    "        strr=\"\"\"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\"\n",
    "        self.vocabulary = list(strr)\n",
    "\n",
    "        self.identity_mat = np.identity(len(self.vocabulary))\n",
    "        texts, labels = [], []\n",
    "        \n",
    "        self.labels = [int(i)-1 for i in df['class'].values]\n",
    "        self.num_classes = len(set(self.labels))\n",
    "        self.length = len(self.labels)\n",
    "        self.texts = df['desc'].values\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raw_text = self.texts[index]\n",
    "        isi_text = self.texts[index]\n",
    "        vocabb= self.vocabulary\n",
    "        data = np.array([self.identity_mat[self.vocabulary.index(i)] for i in list(raw_text) if i in vocabb], dtype=np.float32)\n",
    "\n",
    "        if len(data) == 0:\n",
    "            data = np.zeros((self.max_length, len(self.vocabulary)), dtype=np.float32)\n",
    "        \n",
    "        \n",
    "        elif self.max_length > len(data) > 0 :\n",
    "            data = np.concatenate((data, np.zeros((-(len(data) - self.max_length), len(self.vocabulary)), dtype=np.float32)))\n",
    "        \n",
    "        elif  self.max_length < len(data):\n",
    "            data = data[:self.max_length]\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=TextDataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_siz=int(0.9*120000)\n",
    "valid_siz=120000-train_siz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=128, num_workers=2, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(characterConvolutionNetwork.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.train=False\n",
    "        self.model_dict_path='./model_dict.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf=Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnf.train:\n",
    "    for i in range(epochs):\n",
    "        running_loss=0\n",
    "        for j,data in enumerate(trainloader,0):\n",
    "            x,y=data\n",
    "            x=Variable(x)\n",
    "            y=Variable(y)\n",
    "            optimizer.zero_grad()\n",
    "            out=characterConvolutionNetwork(x)\n",
    "            loss=nll_loss(out,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if j%100==0:\n",
    "                print(loss.data)\n",
    "else:\n",
    "    plt1=cv2.imread('./plot1.png')\n",
    "    plt2=cv2.imread('./plot2.png')\n",
    "\n",
    "    fig=plt.figure(figsize=(20,12))\n",
    "    r=1\n",
    "    c=2\n",
    "    fig.add_subplot(r,c,1)\n",
    "    plt.imshow(plt1,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    fig.add_subplot(r,c,2)\n",
    "    plt.imshow(plt2,cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnf.train:\n",
    "    torch.save(characterConvolutionNetwork.state_dict(), cnf.model_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharacterConvolutionNetwork(4)\n",
    "model.load_state_dict(torch.load('./model_dict.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_df))\n",
    "testset=TextDataset(test_df)\n",
    "# print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(testset,batch_size=128, num_workers=2, drop_last=True, shuffle=True)\n",
    "# print(len(testloader))\n",
    "# print(next(iter(testloader)))\n",
    "pr=[]\n",
    "ac=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "match=0\n",
    "# print(testloader)\n",
    "# for j,data in enumerate(testloader,0):\n",
    "#   x,y=data\n",
    "#   x=Variable(x)\n",
    "#   y=Variable(y)\n",
    "#   print(j)\n",
    "for j,data in enumerate(testloader,0):\n",
    "        m1=0\n",
    "        x,y=data\n",
    "        # print(x,y)\n",
    "        x=Variable(x)\n",
    "        y=Variable(y)\n",
    "        out=model(torch.reshape(x,(128,1014,68)))\n",
    "        # print(out[1])\n",
    "        lab = []\n",
    "        for i in out:\n",
    "            mx=-1e9\n",
    "            midx=0\n",
    "            for x in range(4):\n",
    "                if i[x]>mx:\n",
    "                    mx=i[x]\n",
    "                    midx=x\n",
    "            lab.append(midx)\n",
    "        # print(lab)\n",
    "        for i in range(128):\n",
    "            if y[i]==lab[i]:\n",
    "                match+=1\n",
    "            pr.append(lab[i])\n",
    "            ac.append(y[i])\n",
    "        # break\n",
    "print(\"accuracy\",str(match*100/len(testset)),\"%%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sm(pred,test,i,case):\n",
    "    cnt=0\n",
    "    for x in range(len(pred)):\n",
    "        if case=='tp':\n",
    "            if pred[x]==i and test[x]==i:\n",
    "                cnt+=1\n",
    "        elif case=='tn':\n",
    "            if pred[x]!=i and test[x]!=i:\n",
    "                cnt+=1\n",
    "        elif case=='fp':\n",
    "            if pred[x]!=i and test[x]==i:\n",
    "                cnt+=1\n",
    "        elif case=='fn':\n",
    "            if pred[x]==i and test[x]!=i:\n",
    "                cnt+=1\n",
    "    return cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMet(pred,test,nclass):\n",
    "    tp=[0 for i in range(nclass)]\n",
    "    tn=[0 for i in range(nclass)]\n",
    "    fp=[0 for i in range(nclass)]\n",
    "    fn=[0 for i in range(nclass)]\n",
    "    for i in range(nclass):\n",
    "        tp[i]=sm(pred,test,i,'tp')\n",
    "        tn[i]=sm(pred,test,i,'tn')\n",
    "        fp[i]=sm(pred,test,i,'fp')\n",
    "        fn[i]=sm(pred,test,i,'fn')\n",
    "    return tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp,tn,fp,fn=findMet(pred=ac,test=pr,nclass=4)\n",
    "acc=sum(tp)+sum(tn)\n",
    "print(sum(tp))\n",
    "acc/=(sum(tp)+sum(tn)+sum(fp)+sum(fn))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_sc=accuracy_score(ac,pr)\n",
    "pr_sc=precision_score(ac,pr,average=None).tolist()\n",
    "rc_sc=recall_score(ac,pr,average=None).tolist()\n",
    "f1_sc=f1_score(ac,pr,average=None).tolist()\n",
    "print(\"accuracy\",100*ac_sc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "classes=[i for i in range(1,5)]\n",
    "ax.bar(classes,pr_sc,width=0.5)\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('Precision Score')\n",
    "plt.title('Precision Score vs Class for AG\\'s NEWS dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "classes=[i for i in range(1,5)]\n",
    "ax.bar(classes,rc_sc,width=0.5)\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('Recall Score')\n",
    "plt.title('Recall vs Class for AG\\'s NEWS dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "classes=[i for i in range(1,5)]\n",
    "ax.bar(classes,f1_sc,width=0.5)\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Class for AG\\'s NEWS dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_sc.insert(0,'Precision')\n",
    "rc_sc.insert(0,'Recall')\n",
    "f1_sc.insert(0,'F1_score')\n",
    "# print(x)\n",
    "heading=['Type','Class 1','Class 2','Class 3','Class 4']\n",
    "table=[heading,pr_sc,rc_sc,f1_sc]\n",
    "# print(table)\n",
    "print(tabulate.tabulate(table,headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'./dbpedia/train.csv')\n",
    "train_df=pd.DataFrame(data,columns=[\"class\",\"title\",\"desc\"])\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'./dbpedia/test.csv')\n",
    "test_df1=pd.DataFrame(data,columns=[\"class\",\"title\",\"desc\"])\n",
    "print(test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset=TextDataset(test_df1)\n",
    "model1 = CharacterConvolutionNetwork(14)\n",
    "model1.load_state_dict(torch.load('./dbpedia_model_dict.pth'))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(testset,batch_size=128, num_workers=2, drop_last=True, shuffle=True)\n",
    "pr1=[]\n",
    "ac1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "match=0\n",
    "for j,data in enumerate(testloader,0):\n",
    "        # print(j)\n",
    "        m1=0\n",
    "        x,y=data\n",
    "        x=Variable(x)\n",
    "        y=Variable(y)\n",
    "        out=model1(torch.reshape(x,(128,1014,68)))\n",
    "        lab=[]\n",
    "        for i in out:\n",
    "            mx=-1e9\n",
    "            midx=0\n",
    "            for x in range(14):\n",
    "                if i[x]>mx:\n",
    "                    mx=i[x]\n",
    "                    midx=x\n",
    "            lab.append(midx)\n",
    "        for i in range(128):\n",
    "            if y[i]==lab[i]:\n",
    "                match+=1\n",
    "            pr1.append(lab[i])\n",
    "            ac1.append(y[i])\n",
    "print(\"accuracy\",str(match*100/len(testset)),\"%%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp,tn,fp,fn=findMet(pred=ac1,test=pr1,nclass=14)\n",
    "acc=sum(tp)+sum(tn)\n",
    "acc/=(sum(tp)+sum(tn)+sum(fp)+sum(fn))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_sc=accuracy_score(ac1,pr1).tolist()\n",
    "pr_sc=precision_score(ac1,pr1,average=None).tolist()\n",
    "rc_sc=recall_score(ac1,pr1,average=None).tolist()\n",
    "f1_sc=f1_score(ac1,pr1,average=None).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "classes=[i for i in range(1,15)]\n",
    "ax.bar(classes,pr_sc,width=0.5)\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('Precision Score')\n",
    "plt.title('Precision Score vs Class for DBPedia ontology dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "classes=[i for i in range(1,15)]\n",
    "ax.bar(classes,rc_sc,width=0.4)\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall vs Class for DBPedia ontology dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "classes=[i for i in range(1,15)]\n",
    "ax.bar(classes,f1_sc,width=0.5)\n",
    "plt.xlabel('CLASS')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Class for DBPedia ontology dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_sc=accuracy_score(ac1,pr1).tolist()\n",
    "pr_sc=precision_score(ac1,pr1,average=None).tolist()\n",
    "rc_sc=recall_score(ac1,pr1,average=None).tolist()\n",
    "f1_sc=f1_score(ac1,pr1,average=None).tolist()\n",
    "print(\"accuracy\",100*ac_sc,\"%\")\n",
    "pr_sc.insert(0,'Precision')\n",
    "rc_sc.insert(0,'Recall')\n",
    "f1_sc.insert(0,'F1_score')\n",
    "# print(x)\n",
    "heading=['Type']\n",
    "for i in range(1,15):\n",
    "    heading.append('Class'+str(i))\n",
    "table=[heading,pr_sc,rc_sc,f1_sc]\n",
    "t1=[]\n",
    "for i in range(15):\n",
    "    temp=[]\n",
    "    for j in range(4):\n",
    "        temp.append(table[j][i])\n",
    "    t1.append(temp)\n",
    "        \n",
    "# print(t1)\n",
    "print(tabulate.tabulate(t1,headers='firstrow'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "074853cce0e3713ccfcb7e261f78f2efebea7397adf5734306b89ba5e637d493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
